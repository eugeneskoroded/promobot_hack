{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cb5e5b0-c21b-43cf-a0c5-0e41a040b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e70fb58d-8036-417c-99d0-4c30ccba2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82b5c182-a5f4-4e0b-a92e-f1ba26b89f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/final_train.csv\")\n",
    "test = pd.read_csv(\"data/final_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bda38934-0d0f-4e2b-8fb1-40c8c4d4fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entailment_score(query: str, premise: str) -> float:\n",
    "    with torch.inference_mode():\n",
    "        out = model(**tokenizer(query, premise, return_tensors='pt', truncation=True, max_length=512).to(model.device))\n",
    "        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n",
    "    \n",
    "    result = {v: proba[k] for k, v in model.config.id2label.items()}\n",
    "\n",
    "    return result[\"entailment\"]\n",
    "\n",
    "\n",
    "def get_entailments_scores(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    entailments = []\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        incident, group, theme = row[\"Текст инцидента\"], row[\"Группа тем\"], row[\"Тема\"]\n",
    "\n",
    "        entailments.append(get_entailment_score(incident, group + \", \" + theme))\n",
    "\n",
    "    return entailments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be54dcb1-a53d-41e7-82c2-48b89a866510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsGenerator:\n",
    "    \n",
    "    def __init__(self, model_name, model_length, batch_size):\n",
    "        self.model_name = model_name.split('/')[-1]\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(\"cuda\")\n",
    "        self.model_length = model_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "        \n",
    "    def create_embeddings(self, texts):\n",
    "        batches = [texts[i:i + self.batch_size] for i in range(0, len(texts), self.batch_size)]\n",
    "    \n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "    \n",
    "            for batch in tqdm(batches):\n",
    "                encoded_input = self.tokenizer(batch, padding=True, truncation=True, return_tensors='pt', max_length=self.model_length)\n",
    "                encoded_input = {key: val.to('cuda') for key, val in encoded_input.items()}\n",
    "    \n",
    "                model_output = self.model(**encoded_input)\n",
    "                \n",
    "                embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "                \n",
    "                sentence_embeddings = embedding.tolist()\n",
    "                embeddings.extend(sentence_embeddings)\n",
    "    \n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def create_datasets(self, train, test):\n",
    "        train_, test_ = train.copy(), test.copy()\n",
    "\n",
    "        train_embeddings = pd.DataFrame(self.create_embeddings(train_[\"Текст инцидента\"].to_list()))\n",
    "        test_embeddings = pd.DataFrame(self.create_embeddings(test_[\"Текст инцидента\"].to_list()))\n",
    "\n",
    "        train_ = pd.concat([train_, train_embeddings], axis=1)\n",
    "        test_ = pd.concat([test_, test_embeddings], axis=1)\n",
    "\n",
    "        return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a632c94-6421-400d-885b-52eef6001646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fa6b12fa494c6f99a948e8e96ff811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entailments = get_entailments_scores(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3e0d2b5-66e1-4b62-9085-c6f677e14988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d71c9d53a74c51809b8ba88df0c5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4853b2d35eec4d4198baef06fdb58e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c837509a44207b224b3d439e597d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6954686ab946bd8ed45fdf1035fb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a421a8bfbc9c4d33900ca32cc66d62bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_generator = EmbeddingsGenerator(\n",
    "    model_name=\"DeepPavlov/rubert-base-cased-sentence\", model_length=512, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5aeff32-7310-4552-bf88-eb3f2a09d323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6af6fa874b4de7a1541c65bfcab39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dea552b1ff41d28f24b306515b5d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_with_embeddings, test_with_embeddings = embedding_generator.create_datasets(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80959900-917a-468d-b424-75fd6ffd1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_embeddings.to_csv(\"data/train_with_embeddings_rubert-base-cased-sentence.csv\", index=False)\n",
    "test_with_embeddings.to_csv(\"data/test_with_embeddings_rubert-base-cased-sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0b3ab-71de-4ea2-820a-96fb74034eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
