{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b94c1a-a130-42c5-b7db-890a50412234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc89f4f5-5004-4358-b4d6-97eed563b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim: int, device: str = \"cuda\"):\n",
    "        super().__init__()\n",
    "                        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(dim, dim, device=device),\n",
    "            nn.BatchNorm1d(dim, device=device),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        return self.linear(x)\n",
    "    \n",
    "    \n",
    "class HierarchicalSoftmax(nn.Module):\n",
    "    \n",
    "    def __init__(self, tree: Dict[int, List[int]]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tree = tree\n",
    "        self.specified_indexes_list = [list(tree.keys())]\n",
    "        \n",
    "        for head in tree.keys():\n",
    "            self.specified_indexes_list.append(tree[head])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.clone()\n",
    "        \n",
    "        for specified_indexes in self.specified_indexes_list:\n",
    "            sub_tensor = x[:, specified_indexes]\n",
    "        \n",
    "            softmax_result = F.softmax(sub_tensor, dim=1)\n",
    "        \n",
    "            x[:, specified_indexes] = softmax_result\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim: int, hidden_dim: int, num_classes: int, n_layers: int = 1, device: str = \"cuda\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input = nn.Linear(embed_dim, hidden_dim, device=device)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layers = nn.ModuleList([Layer(hidden_dim, device) for _ in range(n_layers)])\n",
    "        self.output = nn.Linear(hidden_dim, num_classes, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2d8970-6b6e-4efc-ad49-6be21d3f8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model, encoder, tree and reversed mapping\n",
    "\n",
    "model = Model(embed_dim=1524, num_classes=221, n_layers=1, hidden_dim=1024).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"model/final_model_for_deploying_roma\"))\n",
    "\n",
    "tree = pickle.load(open(\"model/tree\", \"rb\"))\n",
    "reversed_mapping = pickle.load(open(\"model/reversed_mapping\", \"rb\"))\n",
    "\n",
    "encoder = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\").to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f32138-48d5-4d1c-b9eb-65885119c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def predict(output: torch.Tensor, tree: Dict[int, List[int]]):\n",
    "    softmax = HierarchicalSoftmax(tree)\n",
    "    \n",
    "    output = softmax(output)\n",
    "    \n",
    "    tree_heads = list(tree.keys())\n",
    "    \n",
    "    groups_prob = output[:, tree_heads]\n",
    "    \n",
    "    groups_index = groups_prob.argmax(dim=1).tolist()\n",
    "    \n",
    "    indexes = []\n",
    "    for k, gi in enumerate(tqdm(groups_index)):\n",
    "        theme_index = output[:, tree[gi]].argmax(dim=1)[k].item()\n",
    "        \n",
    "        indexes.append([gi, tree[gi][theme_index]])\n",
    "        \n",
    "    return indexes\n",
    "\n",
    "\n",
    "def make_embeddings(encoder, tokenizer, texts):\n",
    "    with torch.no_grad():\n",
    "        x = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(DEVICE)\n",
    "    \n",
    "        y = encoder(**x).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def make_predict(model: Model, \n",
    "                 input_tensors: torch.Tensor, \n",
    "                 tree: Dict[int, List[int]],\n",
    "                 reversed_mapping: Dict[int, str]) -> Dict[str, str]:\n",
    "\n",
    "    predictions = predict(model(input_tensors), tree)\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    for pred in predictions:\n",
    "        results.append({\n",
    "            \"group\": reversed_mapping[pred[0]].replace(\"Группа: \", \"\"),\n",
    "            \"theme\": reversed_mapping[pred[1]]\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1972106-b49e-4caf-b639-c4b82dd27e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test = pd.read_csv(\"test.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f03633a-6394-4f7f-a98d-7f62679042b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test_texts = submission_test[\"Текст инцидента\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c52e84-e731-454a-b865-880e82500e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3e47b8c9eb47c4901ad288c6ecf9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9743 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_embeddings = []\n",
    "\n",
    "for text in tqdm(submission_test_texts):\n",
    "    my_embeddings.append(make_embeddings(encoder, tokenizer, text))\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a59b3-021f-4ab6-9b3a-44e02c91389d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
